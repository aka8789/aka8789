# -*- coding: utf-8 -*-
"""PredictingEmployeeAttrition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E8ykwSbpyO78-LVdjT35dhxd9RfsGTqr
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')

# Convert the target variable 'Attrition' into binary values
label_encoder = LabelEncoder()
data['Attrition'] = label_encoder.fit_transform(data['Attrition'])  # 1: Yes, 0: No

# Handle binary categorical columns, like 'Y'/'N' or 'Yes'/'No'
binary_columns = ['Gender', 'OverTime', 'Attrition']
for col in binary_columns:
    data[col] = label_encoder.fit_transform(data[col])

# Map 'Y'/'N' values in case they appear in any other columns
data = data.replace({'Y': 1, 'N': 0})

# One-hot encoding for other categorical columns with more than two categories
data = pd.get_dummies(data, columns=['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus'], drop_first=True)

# Standardizing the numeric columns
scaler = StandardScaler()
numeric_features = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction',
                    'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome',
                    'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating',
                    'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',
                    'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
                    'YearsSinceLastPromotion', 'YearsWithCurrManager']
data[numeric_features] = scaler.fit_transform(data[numeric_features])

# Splitting data into training and testing sets
X = data.drop('Attrition', axis=1)
y = data['Attrition']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training the Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Making predictions
y_pred = model.predict(X_test)

# Evaluating the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Visualizing the Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
model.predict(X_test)